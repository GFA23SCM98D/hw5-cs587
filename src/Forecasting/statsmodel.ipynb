{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce717c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from github import Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub Token\n",
    "token = \"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\"\n",
    "\n",
    "# GitHub repositories\n",
    "repositories = [\n",
    "    \"openai/openai-cookbook\",\n",
    "    \"openai/openai-python\",\n",
    "    \"openai/openai-quickstart-python\",\n",
    "    \"milvus-io/pymilvus\",\n",
    "    \"SeleniumHQ/selenium\",\n",
    "    \"golang/go\",\n",
    "    \"google/go-github\",\n",
    "    \"angular/material\",\n",
    "    \"angular/angular-cli\",\n",
    "    \"SebastianM/angular-google-maps\",\n",
    "    \"d3/d3\",\n",
    "    \"facebook/react\",\n",
    "    \"tensorflow/tensorflow\",\n",
    "    \"keras-team/keras\",\n",
    "    \"pallets/flask\"\n",
    "]\n",
    "\n",
    "# GitHub API client\n",
    "g = Github(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf433e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get time series data for an issue metric\n",
    "def get_time_series_data(repo_name, metric):\n",
    "    repo = g.get_repo(repo_name)\n",
    "    time_series = []\n",
    "\n",
    "    # Get issue metric data\n",
    "    if metric == \"issues_created\":\n",
    "        for issue in repo.get_issues(state=\"all\"):\n",
    "            time_series.append({\"date\": issue.created_at.date(), \"count\": 1})\n",
    "    elif metric == \"issues_closed\":\n",
    "        for issue in repo.get_issues(state=\"all\"):\n",
    "            if issue.closed_at:\n",
    "                time_series.append({\"date\": issue.closed_at.date(), \"count\": 1})\n",
    "\n",
    "    # Convert data to DataFrame\n",
    "    df = pd.DataFrame(time_series)\n",
    "    df = df.groupby(\"date\").sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot and save forecast\n",
    "def plot_and_save_forecast(forecast, metric):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(forecast.index, forecast[\"yhat\"], label=\"Forecast\")\n",
    "    ax.fill_between(forecast.index, forecast[\"yhat_lower\"], forecast[\"yhat_upper\"], alpha=0.3)\n",
    "    ax.set_title(f\"{metric.capitalize()} Forecast\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend()\n",
    "    plt.savefig(f\"{metric}_forecast.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform forecasting for each metric\n",
    "for metric in [\"issues_created\", \"issues_closed\", \"pulls\", \"commits\", \"branches\", \"contributors\", \"releases\"]:\n",
    "    all_repo_df = pd.DataFrame()\n",
    "\n",
    "    # Get time series data for each repository\n",
    "    for repo_name in repositories:\n",
    "        df = get_time_series_data(repo_name, metric)\n",
    "        df[\"repo_name\"] = repo_name\n",
    "        all_repo_df = pd.concat([all_repo_df, df])\n",
    "\n",
    "    # Pivot the DataFrame to have repositories as columns\n",
    "    all_repo_df = all_repo_df.pivot(columns=\"repo_name\", values=\"count\")\n",
    "\n",
    "    # Fill missing values with 0\n",
    "    all_repo_df = all_repo_df.fillna(0)\n",
    "\n",
    "    # Perform time series forecasting for each repository\n",
    "    for repo_name in repositories:\n",
    "        # Get data for the repository\n",
    "        repo_data = all_repo_df[repo_name].reset_index()\n",
    "\n",
    "        # Set the date as the index\n",
    "        repo_data = repo_data.set_index(\"date\")\n",
    "\n",
    "        # Perform time series forecasting using SARIMAX\n",
    "        model = sm.tsa.SARIMAX(repo_data, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n",
    "        results = model.fit()\n",
    "\n",
    "        # Make future predictions\n",
    "        future = pd.date_range(start=repo_data.index[-1], periods=365, freq=\"D\")\n",
    "        forecast = results.get_forecast(steps=len(future))\n",
    "        forecast_df = forecast.summary_frame()\n",
    "\n",
    "        # Plot and save forecast\n",
    "        plot_and_save_forecast(forecast_df, metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
